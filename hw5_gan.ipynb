{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from hw5_utils import BASE_URL, download, GANDataset\n",
    "\n",
    "\n",
    "class DNet(nn.Module):\n",
    "    \"\"\"This is discriminator network.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DNet, self).__init__()\n",
    "        \n",
    "        # TODO: implement layers here\n",
    "        self.conv = nn.Conv\n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        # TODO: implement weight initialization here\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: complete forward function\n",
    "        pass\n",
    "\n",
    "\n",
    "class GNet(nn.Module):\n",
    "    \"\"\"This is generator network.\"\"\"\n",
    "\n",
    "    def __init__(self, zdim):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            zdim: dimension for latent variable.\n",
    "        \"\"\"\n",
    "        super(GNet, self).__init__()\n",
    "\n",
    "        # TODO: implement layers here\n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        # TODO: implement weight initialization here\n",
    "        pass\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            z: latent variables used to generate images.\n",
    "        \"\"\"\n",
    "        # TODO: complete forward function\n",
    "        pass\n",
    "\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, zdim=64):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            zdim: dimension for latent variable.\n",
    "        \"\"\"\n",
    "        torch.manual_seed(2)\n",
    "        self._dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self._zdim = zdim\n",
    "        self.disc = DNet().to(self._dev)\n",
    "        self.gen = GNet(self._zdim).to(self._dev)\n",
    "\n",
    "    def _get_loss_d(self, batch_size, batch_data, z):\n",
    "        \"\"\"This function computes loss for discriminator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size: #data per batch.\n",
    "            batch_data: data from dataset.\n",
    "            z: random latent variable.\n",
    "        \"\"\"\n",
    "        # TODO: implement discriminator's loss function\n",
    "        return loss_d\n",
    "\n",
    "    def _get_loss_g(self, batch_size, z):\n",
    "        \"\"\"This function computes loss for generator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size: #data per batch.\n",
    "            z: random latent variable.\n",
    "        \"\"\"\n",
    "        # TODO: implement generator's loss function\n",
    "        return loss_g\n",
    "\n",
    "    def train(self, iter_d=1, iter_g=1, n_epochs=100, batch_size=256, lr=0.0002):\n",
    "\n",
    "        # first download\n",
    "        f_name = \"train-images-idx3-ubyte.gz\"\n",
    "        download(BASE_URL + f_name, f_name)\n",
    "\n",
    "        print(\"Processing dataset ...\")\n",
    "        train_data = GANDataset(\n",
    "            f\"./data/{f_name}\",\n",
    "            self._dev,\n",
    "            transform=transforms.Compose([transforms.Normalize((0.0,), (255.0,))]),\n",
    "        )\n",
    "        print(f\"... done. Total {len(train_data)} data entries.\")\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "        dopt = optim.Adam(self.disc.parameters(), lr=lr, weight_decay=0.0)\n",
    "        dopt.zero_grad()\n",
    "        gopt = optim.Adam(self.gen.parameters(), lr=lr, weight_decay=0.0)\n",
    "        gopt.zero_grad()\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            for batch_idx, data in tqdm(\n",
    "                enumerate(train_loader), total=len(train_loader)\n",
    "            ):\n",
    "\n",
    "                z = 2 * torch.rand(data.size()[0], self._zdim, device=self._dev) - 1\n",
    "\n",
    "                if batch_idx == 0 and epoch == 0:\n",
    "                    plt.imshow(data[0, 0, :, :].detach().cpu().numpy())\n",
    "                    plt.savefig(\"goal.pdf\")\n",
    "\n",
    "                if batch_idx == 0 and epoch % 10 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        tmpimg = self.gen(z)[0:64, :, :, :].detach().cpu()\n",
    "                    save_image(\n",
    "                        tmpimg, \"test_{0}.png\".format(epoch), nrow=8, normalize=True\n",
    "                    )\n",
    "\n",
    "                dopt.zero_grad()\n",
    "                for k in range(iter_d):\n",
    "                    loss_d = self._get_loss_d(batch_size, data, z)\n",
    "                    loss_d.backward()\n",
    "                    dopt.step()\n",
    "                    dopt.zero_grad()\n",
    "\n",
    "                gopt.zero_grad()\n",
    "                for k in range(iter_g):\n",
    "                    loss_g = self._get_loss_g(batch_size, z)\n",
    "                    loss_g.backward()\n",
    "                    gopt.step()\n",
    "                    gopt.zero_grad()\n",
    "\n",
    "            print(f\"E: {epoch}; DLoss: {loss_d.item()}; GLoss: {loss_g.item()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gan = GAN()\n",
    "    gan.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
